{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d300c96f-ba29-49a7-9a44-ec13a53dca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "OpenCV version: 4.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c78c9a80-000f-4a13-b220-79c8e04a0df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Found 152 total videos.\n",
      "✅ Saved 152 sampled video paths to selected_videos.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# 📂 Path to your ISLVT videos folder\n",
    "DATASET_DIR = r\"C:\\Users\\param\\OneDrive\\Desktop\\Main\\Coding\\1M1B\\Workplace\\credentials\\model\\videos\"  # <-- Change to your WLASL folder\n",
    "\n",
    "# Find all MP4 files\n",
    "all_videos = []\n",
    "for root, _, files in os.walk(DATASET_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith(\".MOV\"):\n",
    "            all_videos.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"📊 Found {len(all_videos)} total videos.\")\n",
    "\n",
    "# 🎯 Randomly pick 500\n",
    "sample_size = 500 if len(all_videos) >= 500 else len(all_videos)\n",
    "sampled_videos = random.sample(all_videos, sample_size)\n",
    "\n",
    "# Save the selected paths to a text file for later use\n",
    "with open(\"selected_videos.txt\", \"w\") as f:\n",
    "    for video in sampled_videos:\n",
    "        f.write(video + \"\\n\")\n",
    "\n",
    "print(f\"✅ Saved {sample_size} sampled video paths to selected_videos.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceb587fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved landmarks for 75 sleep well  (2) - Shape: (105, 126)\n",
      "✅ Saved landmarks for 33 pune cold  - Shape: (138, 126)\n",
      "✅ Saved landmarks for 71 birds sky fly   - Shape: (267, 126)\n",
      "✅ Saved landmarks for 25 raju first come tanu after - Shape: (270, 126)\n",
      "✅ Saved landmarks for 60 shoes dirty  (2) - Shape: (132, 126)\n",
      "✅ Saved landmarks for 70 dog  pet animal  - Shape: (165, 126)\n",
      "✅ Saved landmarks for 70 dog  pet animal  (2) - Shape: (171, 126)\n",
      "✅ Saved landmarks for 11 grand mother market go  - Shape: (219, 126)\n",
      "✅ Saved landmarks for 3 family big  (2) - Shape: (129, 126)\n",
      "✅ Saved landmarks for 39 egg white  (2) - Shape: (147, 126)\n",
      "✅ Saved landmarks for 6 girl hungry  - Shape: (189, 126)\n",
      "✅ Saved landmarks for 22 we this week holiday  - Shape: (174, 126)\n",
      "✅ Saved landmarks for 76 his hair  comb will  - Shape: (246, 126)\n",
      "✅ Saved landmarks for 41 dress color green  (2) - Shape: (141, 126)\n",
      "✅ Saved landmarks for 69 Cat  apet animal  - Shape: (174, 126)\n",
      "✅ Saved landmarks for 44 i black coffe like  (2) - Shape: (168, 126)\n",
      "✅ Saved landmarks for 40 my bag color blue  - Shape: (171, 126)\n",
      "✅ Saved landmarks for 21 we night go out  - Shape: (153, 126)\n",
      "✅ Saved landmarks for 30 hot very here  - Shape: (153, 126)\n",
      "✅ Saved landmarks for 72 i  bathroom go   (2) - Shape: (177, 126)\n",
      "✅ Saved landmarks for 71 birds sky fly    - Shape: (270, 126)\n",
      "✅ Saved landmarks for 60 shoes dirty  - Shape: (132, 126)\n",
      "✅ Saved landmarks for 20 this day i inform you  (2) - Shape: (141, 126)\n",
      "✅ Saved landmarks for 14 baby cute  (2) - Shape: (120, 126)\n",
      "✅ Saved landmarks for 17 we place see go which  - Shape: (201, 126)\n",
      "✅ Saved landmarks for 24 this year  feb 29 date leap not  (2) - Shape: (291, 126)\n",
      "✅ Saved landmarks for 7 marraige today  (2) - Shape: (129, 126)\n",
      "✅ Saved landmarks for 34 pizza food healthy not  - Shape: (222, 126)\n",
      "✅ Saved landmarks for 1 hello you how 2  - Shape: (102, 126)\n",
      "✅ Saved landmarks for 12 grandmother market go will  (2) - Shape: (291, 126)\n",
      "✅ Saved landmarks for 57 shirt white  - Shape: (180, 126)\n",
      "✅ Saved landmarks for 14 baby cute  - Shape: (135, 126)\n",
      "✅ Saved landmarks for 8 aunty plants water  (2) - Shape: (222, 126)\n",
      "✅ Saved landmarks for 48 he drink more  (2) - Shape: (141, 126)\n",
      "✅ Saved landmarks for 46 apple in vitamin-mineral have  - Shape: (243, 126)\n",
      "✅ Saved landmarks for 61 Health important  - Shape: (156, 126)\n",
      "✅ Saved landmarks for 24 this year  feb 29 date leap not  - Shape: (261, 126)\n",
      "✅ Saved landmarks for 63 i her give ten rupees have   - Shape: (228, 126)\n",
      "✅ Saved landmarks for 39 egg white  - Shape: (153, 126)\n",
      "✅ Saved landmarks for 19 this work my not  - Shape: (156, 126)\n",
      "✅ Saved landmarks for 20 this day i inform you  - Shape: (144, 126)\n",
      "✅ Saved landmarks for 61 Health important  (2) - Shape: (162, 126)\n",
      "✅ Saved landmarks for 16 they apply divorce  (2) - Shape: (195, 126)\n",
      "✅ Saved landmarks for 22 we this week holiday  (2) - Shape: (174, 126)\n",
      "✅ Saved landmarks for 5 boy short  - Shape: (177, 126)\n",
      "✅ Saved landmarks for 12 grandmother market go will  - Shape: (189, 126)\n",
      "✅ Saved landmarks for 50 i fruit fork eat  - Shape: (246, 126)\n",
      "✅ Saved landmarks for 66 ticket cost what  - Shape: (168, 126)\n",
      "✅ Saved landmarks for 54 cookies stale  - Shape: (240, 126)\n",
      "✅ Saved landmarks for 80 floor clean - Shape: (246, 126)\n",
      "✅ Saved landmarks for 77 room in sun  light 2 - Shape: (207, 126)\n",
      "✅ Saved landmarks for 36 children milk drink like  - Shape: (201, 126)\n",
      "✅ Saved landmarks for 6 girl hungry  (2) - Shape: (216, 126)\n",
      "✅ Saved landmarks for 73  my teeth brush  - Shape: (162, 126)\n",
      "✅ Saved landmarks for 2 Home welcome - Shape: (114, 126)\n",
      "✅ Saved landmarks for 16 they apply divorce  - Shape: (204, 126)\n",
      "✅ Saved landmarks for 55 cookies fresh  (2) - Shape: (210, 126)\n",
      "✅ Saved landmarks for 52 cereals protein have   - Shape: (309, 126)\n",
      "✅ Saved landmarks for 5 boy short  (2) - Shape: (177, 126)\n",
      "✅ Saved landmarks for 29 furnac machine near teamrature hot  - Shape: (315, 126)\n",
      "✅ Saved landmarks for 50 i fruit fork eat  (2) - Shape: (177, 126)\n",
      "✅ Saved landmarks for 17 we place see go which  (2) - Shape: (225, 126)\n",
      "✅ Saved landmarks for 32 it cold coffee  (2) - Shape: (159, 126)\n",
      "✅ Saved landmarks for 9 uncle friuts get  (2) - Shape: (156, 126)\n",
      "✅ Saved landmarks for 31 food taste good  - Shape: (138, 126)\n",
      "✅ Saved landmarks for 11 grand mother market go  (2) - Shape: (207, 126)\n",
      "✅ Saved landmarks for 40 my bag color blue  (2) - Shape: (186, 126)\n",
      "✅ Saved landmarks for 48 he drink more  - Shape: (135, 126)\n",
      "✅ Saved landmarks for 43 eyescolor black  - Shape: (165, 126)\n",
      "✅ Saved landmarks for 8 aunty plants water  (2) - Copy - Shape: (222, 126)\n",
      "✅ Saved landmarks for 26 first him eat after i eat  (2) - Shape: (234, 126)\n",
      "✅ Saved landmarks for 76 his hair  comb will  (2) - Shape: (234, 126)\n",
      "✅ Saved landmarks for 68 there zoo in animals many   - Shape: (171, 126)\n",
      "✅ Saved landmarks for 32 it cold coffee  - Shape: (153, 126)\n",
      "✅ Saved landmarks for 81 this comb  wooden - Shape: (168, 126)\n",
      "✅ Saved landmarks for 35 milk health good  - Shape: (165, 126)\n",
      "✅ Saved landmarks for 57 shirt white  (2) - Shape: (216, 126)\n",
      "✅ Saved landmarks for 59 socks torn  - Shape: (150, 126)\n",
      "✅ Saved landmarks for 2 Home welcome - Copy - Shape: (114, 126)\n",
      "✅ Saved landmarks for 68 there zoo in animals many   (2) - Shape: (237, 126)\n",
      "✅ Saved landmarks for 7 marraige today  - Shape: (123, 126)\n",
      "✅ Saved landmarks for 36 children milk drink like  (2) - Shape: (192, 126)\n",
      "✅ Saved landmarks for 10 granfather sick  - Shape: (123, 126)\n",
      "✅ Saved landmarks for 18 i home reach very late  (2) - Shape: (192, 126)\n",
      "✅ Saved landmarks for 73  my teeth brush  (2) - Shape: (153, 126)\n",
      "✅ Saved landmarks for 37 coffee hot  (2) - Shape: (144, 126)\n",
      "✅ Saved landmarks for 45 she money not  - Shape: (123, 126)\n",
      "✅ Saved landmarks for 15 both just seperate  - Shape: (165, 126)\n",
      "✅ Saved landmarks for 62 your hands wash  - Shape: (165, 126)\n",
      "✅ Saved landmarks for 51 Cup color white light  - Shape: (204, 126)\n",
      "✅ Saved landmarks for 9 uncle friuts get  - Shape: (165, 126)\n",
      "✅ Saved landmarks for 67  i paisa five have   - Shape: (177, 126)\n",
      "✅ Saved landmarks for 19 this work my not  (2) - Shape: (177, 126)\n",
      "✅ Saved landmarks for 65 coins many too  - Shape: (150, 126)\n",
      "✅ Saved landmarks for 56 clothes old - Shape: (135, 126)\n",
      "✅ Saved landmarks for 4 mother food cook  - Copy-CokUY0 - Shape: (147, 126)\n",
      "✅ Saved landmarks for 58 pants old  - Shape: (147, 126)\n",
      "✅ Saved landmarks for 65 coins many too  (2) - Shape: (156, 126)\n",
      "✅ Saved landmarks for 75 sleep well  - Shape: (105, 126)\n",
      "✅ Saved landmarks for 54 cookies stale  (2) - Shape: (261, 126)\n",
      "✅ Saved landmarks for 29 furnac machine near teamrature hot  (2) - Shape: (318, 126)\n",
      "✅ Saved landmarks for 15 both just seperate  (2) - Shape: (165, 126)\n",
      "✅ Saved landmarks for 47 cheese topings good  - Shape: (147, 126)\n",
      "✅ Saved landmarks for 13 before grand mother market go finish  - Shape: (210, 126)\n",
      "✅ Saved landmarks for 64 Money american use dollars  -GZoEyI - Shape: (219, 126)\n",
      "✅ Saved landmarks for 46 apple in vitamin-mineral have  (2) - Shape: (240, 126)\n",
      "✅ Saved landmarks for 58 pants  old  - Shape: (141, 126)\n",
      "✅ Saved landmarks for 38 curd sweet  (2) - Shape: (159, 126)\n",
      "✅ Saved landmarks for 3 family big  - Shape: (99, 126)\n",
      "✅ Saved landmarks for 1 hello you how  - Shape: (93, 126)\n",
      "✅ Saved landmarks for 21 we night go out  (2) - Shape: (165, 126)\n",
      "✅ Saved landmarks for 23 christmas month celebration  - Shape: (204, 126)\n",
      "✅ Saved landmarks for 56 clothes old  - Shape: (174, 126)\n",
      "✅ Saved landmarks for 41 dress color green  - Shape: (153, 126)\n",
      "✅ Saved landmarks for 62 your hands wash  (2) - Shape: (186, 126)\n",
      "✅ Saved landmarks for 37 coffee hot  - Shape: (126, 126)\n",
      "✅ Saved landmarks for 28 you work finish  (2) - Shape: (138, 126)\n",
      "✅ Saved landmarks for 79 your Teeth clean 2 - Shape: (144, 126)\n",
      "✅ Saved landmarks for 26 first him eat after i eat  - Shape: (240, 126)\n",
      "✅ Saved landmarks for 49 she live life like queen  (2) - Shape: (225, 126)\n",
      "✅ Saved landmarks for 67  i paisa five have   (2) - Shape: (186, 126)\n",
      "✅ Saved landmarks for 59 socks torn  (2) - Shape: (165, 126)\n",
      "✅ Saved landmarks for 55 cookies fresh  - Shape: (192, 126)\n",
      "✅ Saved landmarks for 52 cereals protein have   (2) - Shape: (324, 126)\n",
      "✅ Saved landmarks for 13 before grand mother market go finish  (2) - Shape: (243, 126)\n",
      "✅ Saved landmarks for 35 milk health good  (2) - Shape: (162, 126)\n",
      "✅ Saved landmarks for 77 room in sun  light  - Shape: (195, 126)\n",
      "✅ Saved landmarks for 10 granfather sick  (2) - Shape: (162, 126)\n",
      "✅ Saved landmarks for 72 i  bathroom go   - Shape: (198, 126)\n",
      "✅ Saved landmarks for 30 hot very here  (2) - Shape: (168, 126)\n",
      "✅ Saved landmarks for 44 i black coffe like  - Shape: (159, 126)\n",
      "✅ Saved landmarks for 53 water cold  - Copy - Shape: (114, 126)\n",
      "✅ Saved landmarks for 74 her  teeth  broke  - Shape: (162, 126)\n",
      "✅ Saved landmarks for 18 i home reach very late  - Shape: (186, 126)\n",
      "✅ Saved landmarks for 49 she live life like queen  - Shape: (213, 126)\n",
      "✅ Saved landmarks for 64 Money american use dollars   - Shape: (219, 126)\n",
      "✅ Saved landmarks for 80 floor clean  (2) - Shape: (276, 126)\n",
      "✅ Saved landmarks for 31 food taste good  (2) - Shape: (144, 126)\n",
      "✅ Saved landmarks for 28 you work finish  - Shape: (159, 126)\n",
      "✅ Saved landmarks for 53 water cold  - Shape: (114, 126)\n",
      "✅ Saved landmarks for 23 christmas month celebration  (2) - Shape: (243, 126)\n",
      "✅ Saved landmarks for 33 pune cold  (2) - Shape: (144, 126)\n",
      "✅ Saved landmarks for 34 pizza food healthy not  (2) - Shape: (231, 126)\n",
      "✅ Saved landmarks for 51 Cup color white light  (2) - Shape: (225, 126)\n",
      "✅ Saved landmarks for 63 i her give ten rupees have   (2) - Shape: (252, 126)\n",
      "✅ Saved landmarks for 66  tickets cost  what  - Shape: (138, 126)\n",
      "✅ Saved landmarks for 45 she money not  (2) - Shape: (150, 126)\n",
      "✅ Saved landmarks for 81 this comb  wooden  (2) - Shape: (159, 126)\n",
      "✅ Saved landmarks for 38 curd sweet  - Shape: (138, 126)\n",
      "✅ Saved landmarks for 4 mother food cook  - Copy - Shape: (147, 126)\n",
      "✅ Saved landmarks for 69 Cat  apet animal  (2) - Shape: (189, 126)\n",
      "✅ Saved landmarks for 47 cheese topings good  (2) - Shape: (132, 126)\n",
      "\n",
      "🎯 Processing Complete!\n",
      "✅ Successfully processed: 152 videos\n",
      "❌ Failed/Skipped: 0 videos\n",
      "\n",
      "🧪 Test load successful! Sample shape: (102, 126)\n",
      "   - Frames: 102\n",
      "   - Features per frame: 126 (should be 126)\n"
     ]
    }
   ],
   "source": [
    "# MediaPipe hands setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Where to save processed landmark data\n",
    "OUTPUT_DIR = \"processed_landmarks\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Read sampled videos\n",
    "with open(\"selected_videos.txt\", \"r\") as f:\n",
    "    video_paths = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Process each video\n",
    "processed_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "for video_path in video_paths:\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        landmarks_all_frames = []\n",
    "        \n",
    "        frame_count = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(rgb_frame)\n",
    "            \n",
    "            # Initialize frame landmarks with zeros (consistent shape: 126 values)\n",
    "            frame_landmarks = [0.0] * 126  # 2 hands × 21 landmarks × 3 coords\n",
    "            \n",
    "            if results.multi_hand_landmarks:\n",
    "                # Process detected hands\n",
    "                for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                    if hand_idx >= 2:  # Only process first 2 hands\n",
    "                        break\n",
    "                        \n",
    "                    # Extract coordinates for this hand\n",
    "                    hand_coords = []\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        hand_coords.extend([lm.x, lm.y, lm.z])\n",
    "                    \n",
    "                    # Place hand data in the correct position\n",
    "                    start_idx = hand_idx * 63  # 63 values per hand\n",
    "                    frame_landmarks[start_idx:start_idx + 63] = hand_coords\n",
    "            \n",
    "            landmarks_all_frames.append(frame_landmarks)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Convert to NumPy array (should work now - consistent shapes!)\n",
    "        landmarks_array = np.array(landmarks_all_frames)\n",
    "        \n",
    "        # Only save if we got some frames\n",
    "        if landmarks_array.shape[0] > 0:\n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"{video_name}_landmarks.npy\"), landmarks_array)\n",
    "            print(f\"✅ Saved landmarks for {video_name} - Shape: {landmarks_array.shape}\")\n",
    "            processed_count += 1\n",
    "        else:\n",
    "            print(f\"⚠️ Skipped {video_name} - No frames processed\")\n",
    "            failed_count += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {video_path}: {e}\")\n",
    "        failed_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"\\n🎯 Processing Complete!\")\n",
    "print(f\"✅ Successfully processed: {processed_count} videos\")\n",
    "print(f\"❌ Failed/Skipped: {failed_count} videos\")\n",
    "\n",
    "# Test load one file to verify\n",
    "if processed_count > 0:\n",
    "    test_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.npy')]\n",
    "    if test_files:\n",
    "        test_data = np.load(os.path.join(OUTPUT_DIR, test_files[0]))\n",
    "        print(f\"\\n🧪 Test load successful! Sample shape: {test_data.shape}\")\n",
    "        print(f\"   - Frames: {test_data.shape[0]}\")\n",
    "        print(f\"   - Features per frame: {test_data.shape[1]} (should be 126)\")\n",
    "else:\n",
    "    print(\"❌ No files were processed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555116d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤟 ISLVT LSTM Model Training\n",
      "==================================================\n",
      "🚀 Starting ISLVT LSTM model training...\n",
      "📁 Loading processed ISLVT landmark data...\n",
      "Found 80 landmark files to process...\n",
      "✅ 1 i am good _landmarks.npy -> 'i am good' (shape: (30, 126))\n",
      "✅ 10 granfather sick _landmarks.npy -> 'granfather sick' (shape: (30, 126))\n",
      "✅ 11 grand mother market go _landmarks.npy -> 'grand mother market go' (shape: (30, 126))\n",
      "✅ 12 grandmother market go will _landmarks.npy -> 'grandmother market go will' (shape: (30, 126))\n",
      "✅ 13 before grand mother market go finish _landmarks.npy -> 'before grand mother market go finish' (shape: (30, 126))\n",
      "\n",
      "📊 Data Loading Summary:\n",
      "✅ Successfully loaded: 80 sequences\n",
      "⚠️ Skipped: 0 files\n",
      "\n",
      "🏷️ Found 80 unique signs:\n",
      "   i am good: 1 videos\n",
      "   granfather sick: 1 videos\n",
      "   grand mother market go: 1 videos\n",
      "   grandmother market go will: 1 videos\n",
      "   before grand mother market go finish: 1 videos\n",
      "   baby cute: 1 videos\n",
      "   both just seperate: 1 videos\n",
      "   they apply divorce: 1 videos\n",
      "   we place see go which: 1 videos\n",
      "   i home reach very late: 1 videos\n",
      "   ... and 70 more\n",
      "\n",
      "⚠️  WARNING: All sentences appear only once!\n",
      "   This means each sentence is unique - typical for sentence-level ISLVT\n",
      "   The model will learn individual sentences, not generalize to new ones\n",
      "   Consider training on individual words instead for better generalization\n",
      "\n",
      "🔍 After filtering (min 1 samples per class):\n",
      "   Final dataset: 80 sequences\n",
      "   Unique classes: 80\n",
      "\n",
      "📊 Final Dataset Shape: (80, 30, 126)\n",
      "🏷️ Unique Signs: 80\n",
      "⚠️  Using random split (no stratification possible with unique samples)\n",
      "\n",
      "🎯 Training samples: 64\n",
      "🧪 Testing samples: 16\n",
      "\n",
      "🧠 Model Architecture:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 128)           130560    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 128)          512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 64)            49408     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 64)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                2640      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,112\n",
      "Trainable params: 199,664\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "\n",
      "🏋️ Starting training...\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 7s 442ms/step - loss: 4.6699 - accuracy: 0.0000e+00 - val_loss: 4.3808 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.6106 - accuracy: 0.0156 - val_loss: 4.3891 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.6770 - accuracy: 0.0156 - val_loss: 4.3970 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.6086 - accuracy: 0.0156 - val_loss: 4.4040 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.4784 - accuracy: 0.0156 - val_loss: 4.4103 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.4715 - accuracy: 0.0156    \n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.4715 - accuracy: 0.0156 - val_loss: 4.4178 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.4733 - accuracy: 0.0312 - val_loss: 4.4211 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.3612 - accuracy: 0.0156 - val_loss: 4.4238 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.4472 - accuracy: 0.0000e+00 - val_loss: 4.4263 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.3893 - accuracy: 0.0156 - val_loss: 4.4278 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.4425 - accuracy: 0.0000e+00Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 4.4425 - accuracy: 0.0000e+00 - val_loss: 4.4302 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 11: early stopping\n",
      "\n",
      "🎉 Training Complete!\n",
      "📊 Test Accuracy: 0.0000\n",
      "📉 Test Loss: 4.3808\n",
      "\n",
      "🔮 Sample Predictions:\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "   ❌ Predicted: 'cereals protein have' | Actual: 'coffee hot' | Confidence: 0.014\n",
      "   ❌ Predicted: 'water cold' | Actual: 'i am good' | Confidence: 0.014\n",
      "   ❌ Predicted: 'children milk drink like' | Actual: 'family big' | Confidence: 0.014\n",
      "   ❌ Predicted: 'water cold' | Actual: 'curd sweet' | Confidence: 0.014\n",
      "   ❌ Predicted: 'water cold' | Actual: 'first him eat after i eat' | Confidence: 0.014\n",
      "\n",
      "💾 Saving model and labels...\n",
      "✅ Model saved: models/islvt_model.h5\n",
      "✅ Labels saved: models/islvt_labels.json\n",
      "✅ Label encoder saved: models/islvt_encoder.pkl\n",
      "✅ Summary saved: models/islvt_summary.json\n",
      "\n",
      "🎉 SUCCESS!\n",
      "🤖 Model trained with 0.0000 accuracy\n",
      "📁 Files created:\n",
      "   - models/islvt_model.h5\n",
      "   - models/islvt_labels.json\n",
      "   - models/islvt_encoder.pkl\n",
      "   - models/islvt_summary.json\n",
      "\n",
      "🚀 Ready to use in your Flask app!\n",
      "Update your .env file:\n",
      "WLASL_MODEL_PATH=./models/islvt_model.h5\n",
      "WLASL_LABELS_PATH=./models/islvt_labels.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "class ISLVTModelTrainer:\n",
    "    def __init__(self, landmarks_dir=\"processed_landmarks\"):\n",
    "        self.landmarks_dir = landmarks_dir\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "    def extract_label_from_filename(self, filename):\n",
    "        \"\"\"\n",
    "        Extract sentence label from ISLVT filename\n",
    "        Format: \"number sentence text _landmarks.npy\"\n",
    "        Example: \"21 we night go out _landmarks.npy\" -> \"we night go out\"\n",
    "        \"\"\"\n",
    "        # Remove file extension and landmarks suffix\n",
    "        basename = filename.replace('_landmarks.npy', '').strip()\n",
    "        \n",
    "        # Split by spaces\n",
    "        parts = basename.split()\n",
    "        \n",
    "        if len(parts) > 1:\n",
    "            # First part is usually a number, rest is the sentence\n",
    "            # Check if first part is a number\n",
    "            try:\n",
    "                int(parts[0])  # If this works, first part is a number\n",
    "                sentence = ' '.join(parts[1:])  # Join the rest as sentence\n",
    "                return sentence.lower().strip()\n",
    "            except ValueError:\n",
    "                # First part is not a number, use entire string\n",
    "                return basename.lower().strip()\n",
    "        else:\n",
    "            # Single word or part\n",
    "            return basename.lower().strip()\n",
    "    \n",
    "    def load_processed_data(self):\n",
    "        \"\"\"Load all processed landmark files and create dataset\"\"\"\n",
    "        print(\"📁 Loading processed ISLVT landmark data...\")\n",
    "        \n",
    "        X_data = []\n",
    "        y_labels = []\n",
    "        loaded_count = 0\n",
    "        skipped_count = 0\n",
    "        filename_to_label = {}\n",
    "        \n",
    "        # Get all .npy files\n",
    "        npy_files = [f for f in os.listdir(self.landmarks_dir) if f.endswith('_landmarks.npy')]\n",
    "        \n",
    "        if len(npy_files) == 0:\n",
    "            raise ValueError(\"No landmark files found! Check your processed_landmarks directory.\")\n",
    "        \n",
    "        print(f\"Found {len(npy_files)} landmark files to process...\")\n",
    "        \n",
    "        for npy_file in npy_files:\n",
    "            try:\n",
    "                # Extract label from filename\n",
    "                label = self.extract_label_from_filename(npy_file)\n",
    "                filename_to_label[npy_file] = label\n",
    "                \n",
    "                # Load landmark data\n",
    "                landmarks = np.load(os.path.join(self.landmarks_dir, npy_file))\n",
    "                \n",
    "                # Skip if too few frames\n",
    "                if landmarks.shape[0] < 10:\n",
    "                    print(f\"⚠️ Skipping {npy_file} - only {landmarks.shape[0]} frames\")\n",
    "                    skipped_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # Pad or truncate to fixed length\n",
    "                max_frames = 30  # Fixed sequence length\n",
    "                if landmarks.shape[0] > max_frames:\n",
    "                    landmarks = landmarks[:max_frames]\n",
    "                else:\n",
    "                    # Pad with zeros\n",
    "                    padding = np.zeros((max_frames - landmarks.shape[0], 126))\n",
    "                    landmarks = np.vstack([landmarks, padding])\n",
    "                \n",
    "                X_data.append(landmarks)\n",
    "                y_labels.append(label)\n",
    "                loaded_count += 1\n",
    "                \n",
    "                if loaded_count <= 5:  # Show first few for verification\n",
    "                    print(f\"✅ {npy_file} -> '{label}' (shape: {landmarks.shape})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error loading {npy_file}: {e}\")\n",
    "                skipped_count += 1\n",
    "        \n",
    "        print(f\"\\n📊 Data Loading Summary:\")\n",
    "        print(f\"✅ Successfully loaded: {loaded_count} sequences\")\n",
    "        print(f\"⚠️ Skipped: {skipped_count} files\")\n",
    "        \n",
    "        # Show label distribution\n",
    "        label_counts = Counter(y_labels)\n",
    "        print(f\"\\n🏷️ Found {len(label_counts)} unique signs:\")\n",
    "        for label, count in label_counts.most_common(10):\n",
    "            print(f\"   {label}: {count} videos\")\n",
    "        if len(label_counts) > 10:\n",
    "            print(f\"   ... and {len(label_counts) - 10} more\")\n",
    "        \n",
    "        if loaded_count == 0:\n",
    "            raise ValueError(\"No data loaded! Check your landmark files and filename patterns.\")\n",
    "        \n",
    "        # Filter out classes with too few samples - ADJUSTED FOR SINGLE SAMPLES\n",
    "        min_samples = 1  # Allow single samples since ISLVT has unique sentences\n",
    "        filtered_X = []\n",
    "        filtered_y = []\n",
    "        \n",
    "        # For sentence-level data with single samples, we'll use all data\n",
    "        # but warn about potential overfitting\n",
    "        if max(label_counts.values()) == 1:\n",
    "            print(f\"\\n⚠️  WARNING: All sentences appear only once!\")\n",
    "            print(f\"   This means each sentence is unique - typical for sentence-level ISLVT\")\n",
    "            print(f\"   The model will learn individual sentences, not generalize to new ones\")\n",
    "            print(f\"   Consider training on individual words instead for better generalization\")\n",
    "            \n",
    "            # Use all data\n",
    "            filtered_X = X_data\n",
    "            filtered_y = y_labels\n",
    "        else:\n",
    "            # Filter normally\n",
    "            for label, count in label_counts.items():\n",
    "                if count >= min_samples:\n",
    "                    indices = [i for i, y in enumerate(y_labels) if y == label]\n",
    "                    for idx in indices:\n",
    "                        filtered_X.append(X_data[idx])\n",
    "                        filtered_y.append(y_labels[idx])\n",
    "        \n",
    "        print(f\"\\n🔍 After filtering (min {min_samples} samples per class):\")\n",
    "        print(f\"   Final dataset: {len(filtered_y)} sequences\")\n",
    "        print(f\"   Unique classes: {len(set(filtered_y))}\")\n",
    "        \n",
    "        if len(filtered_y) == 0:\n",
    "            raise ValueError(\"No data remaining after filtering! All classes had too few samples.\")\n",
    "        \n",
    "        return np.array(filtered_X), np.array(filtered_y)\n",
    "    \n",
    "    def create_lstm_model(self, input_shape, num_classes):\n",
    "        \"\"\"Create LSTM model for sign language recognition\"\"\"\n",
    "        model = Sequential([\n",
    "            # First LSTM layer\n",
    "            LSTM(128, return_sequences=True, input_shape=input_shape),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            \n",
    "            # Second LSTM layer\n",
    "            LSTM(64, return_sequences=True),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            \n",
    "            # Third LSTM layer\n",
    "            LSTM(32),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.4),\n",
    "            \n",
    "            # Dense layers\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_model(self, epochs=50):\n",
    "        \"\"\"Train the LSTM model\"\"\"\n",
    "        print(\"🚀 Starting ISLVT LSTM model training...\")\n",
    "        \n",
    "        # Load data\n",
    "        X, y = self.load_processed_data()\n",
    "        \n",
    "        print(f\"\\n📊 Final Dataset Shape: {X.shape}\")\n",
    "        print(f\"🏷️ Unique Signs: {len(np.unique(y))}\")\n",
    "        \n",
    "        # Encode labels\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        \n",
    "        # Split data - handle single-sample case\n",
    "        if len(set(y)) == len(y):\n",
    "            # Each sample is unique - can't stratify\n",
    "            print(\"⚠️  Using random split (no stratification possible with unique samples)\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y_encoded, test_size=0.2, random_state=42\n",
    "            )\n",
    "        else:\n",
    "            # Normal stratified split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n🎯 Training samples: {len(X_train)}\")\n",
    "        print(f\"🧪 Testing samples: {len(X_test)}\")\n",
    "        \n",
    "        # Create model\n",
    "        model = self.create_lstm_model(\n",
    "            input_shape=(X.shape[1], X.shape[2]),  # (frames, features)\n",
    "            num_classes=len(np.unique(y_encoded))\n",
    "        )\n",
    "        \n",
    "        print(\"\\n🧠 Model Architecture:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "            ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "        ]\n",
    "        \n",
    "        # Train model\n",
    "        print(\"\\n🏋️ Starting training...\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=16,  # Smaller batch size for better training\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        print(f\"\\n🎉 Training Complete!\")\n",
    "        print(f\"📊 Test Accuracy: {test_accuracy:.4f}\")\n",
    "        print(f\"📉 Test Loss: {test_loss:.4f}\")\n",
    "        \n",
    "        # Show some predictions\n",
    "        print(\"\\n🔮 Sample Predictions:\")\n",
    "        predictions = model.predict(X_test[:5])\n",
    "        for i in range(min(5, len(X_test))):\n",
    "            predicted_idx = np.argmax(predictions[i])\n",
    "            actual_idx = y_test[i]\n",
    "            predicted_word = self.label_encoder.classes_[predicted_idx]\n",
    "            actual_word = self.label_encoder.classes_[actual_idx]\n",
    "            confidence = predictions[i][predicted_idx]\n",
    "            \n",
    "            result = \"✅\" if predicted_word == actual_word else \"❌\"\n",
    "            print(f\"   {result} Predicted: '{predicted_word}' | Actual: '{actual_word}' | Confidence: {confidence:.3f}\")\n",
    "        \n",
    "        return model, history, test_accuracy\n",
    "    \n",
    "    def save_model_and_labels(self, model):\n",
    "        \"\"\"Save trained model and label mappings\"\"\"\n",
    "        print(\"\\n💾 Saving model and labels...\")\n",
    "        \n",
    "        # Create models directory\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = \"models/islvt_model.h5\"\n",
    "        model.save(model_path)\n",
    "        print(f\"✅ Model saved: {model_path}\")\n",
    "        \n",
    "        # Create labels dictionary\n",
    "        labels_dict = {}\n",
    "        for i, label in enumerate(self.label_encoder.classes_):\n",
    "            labels_dict[str(i)] = label\n",
    "        \n",
    "        # Save labels\n",
    "        labels_path = \"models/islvt_labels.json\"\n",
    "        with open(labels_path, 'w') as f:\n",
    "            json.dump(labels_dict, f, indent=2)\n",
    "        print(f\"✅ Labels saved: {labels_path}\")\n",
    "        \n",
    "        # Save label encoder\n",
    "        encoder_path = \"models/islvt_encoder.pkl\"\n",
    "        with open(encoder_path, 'wb') as f:\n",
    "            pickle.dump(self.label_encoder, f)\n",
    "        print(f\"✅ Label encoder saved: {encoder_path}\")\n",
    "        \n",
    "        # Create summary\n",
    "        summary = {\n",
    "            \"dataset\": \"ISLVT\",\n",
    "            \"model_info\": {\n",
    "                \"num_classes\": len(self.label_encoder.classes_),\n",
    "                \"input_shape\": [30, 126],  # frames, features\n",
    "                \"architecture\": \"LSTM\",\n",
    "                \"framework\": \"TensorFlow/Keras\"\n",
    "            },\n",
    "            \"classes\": list(self.label_encoder.classes_),\n",
    "            \"files\": {\n",
    "                \"model\": model_path,\n",
    "                \"labels\": labels_path,\n",
    "                \"encoder\": encoder_path\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        summary_path = \"models/islvt_summary.json\"\n",
    "        with open(summary_path, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        print(f\"✅ Summary saved: {summary_path}\")\n",
    "        \n",
    "        return model_path, labels_path\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    print(\"🤟 ISLVT LSTM Model Training\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if required files exist\n",
    "    if not os.path.exists(\"processed_landmarks\"):\n",
    "        print(\"❌ processed_landmarks directory not found!\")\n",
    "        print(\"Make sure you've run the landmark processing step first.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = ISLVTModelTrainer()\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        model, history, accuracy = trainer.train_model(epochs=100)\n",
    "        \n",
    "        # Save model and labels\n",
    "        model_path, labels_path = trainer.save_model_and_labels(model)\n",
    "        \n",
    "        print(f\"\\n🎉 SUCCESS!\")\n",
    "        print(f\"🤖 Model trained with {accuracy:.4f} accuracy\")\n",
    "        print(f\"📁 Files created:\")\n",
    "        print(f\"   - {model_path}\")\n",
    "        print(f\"   - {labels_path}\")\n",
    "        print(f\"   - models/islvt_encoder.pkl\")\n",
    "        print(f\"   - models/islvt_summary.json\")\n",
    "        \n",
    "        print(f\"\\n🚀 Ready to use in your Flask app!\")\n",
    "        print(f\"Update your .env file:\")\n",
    "        print(f\"WLASL_MODEL_PATH=./models/islvt_model.h5\")\n",
    "        print(f\"WLASL_LABELS_PATH=./models/islvt_labels.json\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62daf45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insyncmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
